{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTy1iEs2d42S"
      },
      "source": [
        "#### **Import the required libraries**\n",
        "\n",
        "We will be using a few libraries in this session, import all the required libraries in the cell below one by one as we go through the session.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wp2b4VPPd42U"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import tqdm\n",
        "import yaml\n",
        "from sklearn.metrics import (ConfusionMatrixDisplay, classification_report,\n",
        "                             confusion_matrix)\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "from torchvision.io import read_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlYwVr9Ad42V"
      },
      "source": [
        "#### **Download the dataset**\n",
        "\n",
        "We will be using `CIFAR-10` dataset for this session. The dataset consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. Please download the dataset using the following command.\n",
        "\n",
        "```python\n",
        "!wget https://github.com/ccdsiub/deeplearning-code-management/raw/1.1/CIFAR-10.zip\n",
        "!wget https://github.com/ccdsiub/deeplearning-code-management/raw/1.1/configs/VGG_config.yaml\n",
        "!unzip -q /content/CIFAR-10.zip -d /content/\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uF0CRzmd42W",
        "outputId": "433f35ec-f12d-42b8-ab39-0be26bec0068"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-12 09:51:17--  https://github.com/ccdsiub/deeplearning-code-management/raw/1.1/CIFAR-10.zip\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ccdsiub/deeplearning-code-management/1.1/CIFAR-10.zip [following]\n",
            "--2024-12-12 09:51:17--  https://raw.githubusercontent.com/ccdsiub/deeplearning-code-management/1.1/CIFAR-10.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 57166560 (55M) [application/zip]\n",
            "Saving to: ‘CIFAR-10.zip’\n",
            "\n",
            "CIFAR-10.zip        100%[===================>]  54.52M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-12-12 09:51:18 (371 MB/s) - ‘CIFAR-10.zip’ saved [57166560/57166560]\n",
            "\n",
            "--2024-12-12 09:51:18--  https://github.com/ccdsiub/deeplearning-code-management/raw/1.1/configs/VGG_config.yaml\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ccdsiub/deeplearning-code-management/1.1/configs/VGG_config.yaml [following]\n",
            "--2024-12-12 09:51:18--  https://raw.githubusercontent.com/ccdsiub/deeplearning-code-management/1.1/configs/VGG_config.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 197 [text/plain]\n",
            "Saving to: ‘VGG_config.yaml’\n",
            "\n",
            "VGG_config.yaml     100%[===================>]     197  --.-KB/s    in 0s      \n",
            "\n",
            "2024-12-12 09:51:18 (5.82 MB/s) - ‘VGG_config.yaml’ saved [197/197]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/ccdsiub/deeplearning-code-management/raw/1.1/CIFAR-10.zip\n",
        "!wget https://github.com/ccdsiub/deeplearning-code-management/raw/1.1/configs/VGG_config.yaml\n",
        "!unzip -q CIFAR-10.zip -d ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX9OeiOxnfay"
      },
      "source": [
        "#### **Load configuration file**\n",
        "\n",
        "We will be using a configuration file to store all the required parameters for the model. The configuration file is a YAML file, which is a human-readable data serialization standard that can be used in conjunction with all programming languages and is often used to write configuration files. Create a new file named `config.yaml` and add the following content to it.\n",
        "\n",
        "```yaml\n",
        "data_params:\n",
        "  data_path: \"CIFAR-10/\"\n",
        "```\n",
        "\n",
        "Read the configuration file using the `yaml` library and store the data in a variable named `config`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDn8w76Ena06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b641074c-564b-4b37-bf1b-aba4a93ac0b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'data_params': {'data_path': 'CIFAR-10/', 'train_ratio': 0.8, 'batch_size': 64}, 'model_params': {'num_classes': 10, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'gamma': 0.1, 'step_size': 5, 'num_epochs': 10}}\n"
          ]
        }
      ],
      "source": [
        "file = open(\"VGG_config.yaml\")\n",
        "config = yaml.safe_load(file)\n",
        "file.close()\n",
        "print(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNgBOHn_d42W"
      },
      "source": [
        "#### **Load the dataset**\n",
        "\n",
        "Check the files in the side panel to see if the dataset is downloaded successfully. The dataset is organized in the following way.\n",
        "\n",
        "```\n",
        "CIFAR-10\n",
        " |\n",
        " └───airplane\n",
        " |\n",
        " └───automobile\n",
        " |\n",
        " └───bird\n",
        " |\n",
        " └───cat\n",
        " |\n",
        " └───deer\n",
        " |\n",
        " └───dog\n",
        " |\n",
        " └───frog\n",
        " |\n",
        " └───horse\n",
        " |\n",
        " └───ship\n",
        " |\n",
        " └───truck\n",
        "```\n",
        "\n",
        "Write a class named `CIFAR10Dataset` to load the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaso9Btsd42d"
      },
      "outputs": [],
      "source": [
        "class CIFAR10(torch.utils.data.Dataset):\n",
        "    \"\"\"The CIFAR10 dataset\"\"\"\n",
        "\n",
        "    def __init__(self, root, transform=None, target_transform=None) -> None:\n",
        "        \"\"\"\n",
        "        Initialize the CIFAR10 dataset\n",
        "\n",
        "        :param root: The root directory of the dataset\n",
        "        :type root: str\n",
        "        :param transform: The transform to apply to the data\n",
        "        :type transform: callable\n",
        "        :param target_transform: The transform to apply to the target\n",
        "        :type target_transform: callable\n",
        "\n",
        "        :return: None\n",
        "        :rtype: None\n",
        "        \"\"\"\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.data = []\n",
        "        self.targets = []\n",
        "\n",
        "        self._load_data()\n",
        "\n",
        "    def _load_data(self):\n",
        "        \"\"\"\n",
        "        Load the data from the root directory\n",
        "\n",
        "        :return: None\n",
        "        :rtype: None\n",
        "        \"\"\"\n",
        "        # Load the data\n",
        "        for i, class_name in enumerate(os.listdir(self.root)):\n",
        "            class_dir = os.path.join(self.root, class_name)\n",
        "            for image_name in os.listdir(class_dir):\n",
        "                image_path = os.path.join(class_dir, image_name)\n",
        "                image = read_image(image_path)\n",
        "                self.data.append(image)\n",
        "                self.targets.append(float(i))\n",
        "\n",
        "    def __getitem__(self, index: int) -> tuple:\n",
        "        \"\"\"\n",
        "        Get the item at the given index\n",
        "\n",
        "        :param index: The index of the item\n",
        "        :type index: int\n",
        "\n",
        "        :return: The item at the given index\n",
        "        :rtype: tuple\n",
        "        \"\"\"\n",
        "        img, target = self.data[index], self.targets[index]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Get the length of the dataset\n",
        "\n",
        "        :return: The length of the dataset\n",
        "        :rtype: int\n",
        "        \"\"\"\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tsE_OvVd42d"
      },
      "source": [
        "#### **Preprocess transformations**\n",
        "\n",
        "Insted of loading the entire dataset into memory, and then applying transformations, we will be using `torchvision.transforms` to apply transformations while loading the dataset. We will use the following transformations:\n",
        "\n",
        "1. `ToTensor`: Convert the image to a tensor with pixel values in the range [0, 1].\n",
        "2. `Normalize`: Normalize the tensor with mean and standard deviation.\n",
        "3. `Lambda`: To flatten the image tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaG4dLZbd42d"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ConvertImageDtype(torch.float32),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "])\n",
        "\n",
        "# you can transform the target too if you want (e.g. one hot encode)\n",
        "target_transform = transforms.Lambda(\n",
        "    lambda y: torch.tensor(y, dtype=torch.long))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEIRxQkkd42d"
      },
      "source": [
        "Initialize the `CIFAR10Dataset` class with the `data_path` from the configuration file or you can use `torchvision.Dataset.ImageFolder` to load the dataset. Pass the transformations to the `CIFAR10Dataset` class and load the dataset.\n",
        "You can load the class name from the folder using `os.listdir` for later use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8XafO6Wd42e"
      },
      "outputs": [],
      "source": [
        "data_path = config[\"data_params\"][\"data_path\"]\n",
        "classes = os.listdir(data_path)\n",
        "\n",
        "dataset = CIFAR10(data_path, transform=transform,\n",
        "                  target_transform=target_transform)\n",
        "\n",
        "# dataset = ImageFolder(data_path, transform=transform,\n",
        "                    #  target_transform=target_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tgm-T7Mgd42e"
      },
      "source": [
        "#### **Split the data**\n",
        "\n",
        "Use `torch.utils.data.random_split` to split the dataset into training and validation sets. Use 80% of the data for training and 10% for validation and 10% for testing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9x1iLzb4d42e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8a32260-99c6-4b18-a8a5-43ddd4481422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 48001\n",
            "Test size: 6000\n",
            "Validation size: 5999\n"
          ]
        }
      ],
      "source": [
        "train_size = config[\"data_params\"][\"train_ratio\"]\n",
        "test_size = (1 - train_size) / 2\n",
        "val_size = test_size\n",
        "\n",
        "train_dataset, test_dataset, val_dataset = torch.utils.data.random_split(\n",
        "    dataset, [train_size, test_size, val_size])\n",
        "\n",
        "print(f\"Train size: {len(train_dataset)}\")\n",
        "print(f\"Test size: {len(test_dataset)}\")\n",
        "print(f\"Validation size: {len(val_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eawb00KXd42e"
      },
      "source": [
        "#### **Create data loaders**\n",
        "\n",
        "Use `torch.utils.data.DataLoader` to create data loaders for training, validation, and testing datasets. Use a batch size from the configuration file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7AjA87Wd42e"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=config[\"data_params\"][\"batch_size\"],\n",
        "    num_workers=torch.get_num_threads(),\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=config[\"data_params\"][\"batch_size\"],\n",
        "    num_workers=torch.get_num_threads(),\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=config[\"data_params\"][\"batch_size\"],\n",
        "    num_workers=torch.get_num_threads(),\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVaDvPhbd42f"
      },
      "source": [
        "#### **Initialize the model**\n",
        "\n",
        "Initialize the model and define the loss function, optimizer, and scheduler. Use the loss function as `nn.CrossEntropyLoss`, optimizer as `torch.optim.Adam`, and scheduler as `torch.optim.lr_scheduler.StepLR`. Use the learning rate and step size from the configuration file. Use the device as `cuda` if available, else use `cpu`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-geQ9yVYm7Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e4fada4-dd3d-4cd1-bbb6-7f9d113d8f66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:05<00:00, 97.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = torchvision.models.vgg16(pretrained=True)\n",
        "\n",
        "# Freeze pretrained layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify the fully connected layer\n",
        "num_ftrs = model.classifier[-1].in_features\n",
        "model.classifier[-1] = torch.nn.Linear(num_ftrs, config['model_params']['num_classes'])  # Change the output to 10 classes for CIFAR-10\n",
        "\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHGODD5Yd42f"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=config[\"model_params\"][\"learning_rate\"],\n",
        "    # L2 regularization\n",
        "    weight_decay=config[\"model_params\"][\"weight_decay\"]\n",
        ")\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(\n",
        "    optimizer,\n",
        "    step_size=config[\"model_params\"][\"step_size\"],\n",
        "    gamma=config[\"model_params\"][\"gamma\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkSan24Bd42f"
      },
      "source": [
        "##### **Validation function**\n",
        "\n",
        "Create a function named `validate` to calculate the accuracy of the model on the validation dataset. Use the `model.eval` method to set the model to evaluation mode and use the `torch.no_grad` context manager to disable gradient calculation. Iterate through the validation data loader and calculate the accuracy of the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CgLRWa5d42f"
      },
      "outputs": [],
      "source": [
        "def validate(\n",
        "    model,\n",
        "    val_loader: torch.utils.data.DataLoader,\n",
        "    criterion: torch.nn.Module,\n",
        "    device: torch.device\n",
        ") -> tuple:\n",
        "    \"\"\"\n",
        "    Validate the model\n",
        "\n",
        "    :param model: The model to validate\n",
        "    :type model: torch.nn.Module\n",
        "    :param val_loader: The validation loader\n",
        "    :type val_loader: torch.utils.data.DataLoader\n",
        "    :param criterion: The loss function\n",
        "    :type criterion: torch.nn.Module\n",
        "    :param device: The device to use\n",
        "    :type device: torch.device\n",
        "\n",
        "    :return: The loss, accuracy and predictions\n",
        "    :rtype: tuple\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    y_pred = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    accuracy = correct / len(y_pred)\n",
        "\n",
        "    return val_loss, accuracy, y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHhLskVOd42f"
      },
      "source": [
        "#### **Training function**\n",
        "\n",
        "Write a function named `train` to train the model. Use the `model.train` method to set the model to training mode. Iterate through the training data loader and calculate the loss and accuracy of the model. Use the `optimizer.zero_grad` method to zero the gradients and use the `loss.backward` method to backpropagate the loss. Use the `optimizer.step` method to update the model parameters. Use the `scheduler.step` method to update the learning rate.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8laHd23d42f"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    model: torch.nn.Module,\n",
        "    train_loader: torch.utils.data.DataLoader,\n",
        "    val_loader: torch.utils.data.DataLoader,\n",
        "    criterion: torch.nn.Module,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    scheduler: torch.optim.lr_scheduler.StepLR,\n",
        "    device: torch.device,\n",
        "    num_epochs: int\n",
        ") -> tuple:\n",
        "    \"\"\"\n",
        "    Train the model\n",
        "\n",
        "    :param model: The model to train\n",
        "    :type model: torch.nn.Module\n",
        "    :param train_loader: The training loader\n",
        "    :type train_loader: torch.utils.data.DataLoader\n",
        "    :param val_loader: The validation loader\n",
        "    :type val_loader: torch.utils.data.DataLoader\n",
        "    :param criterion: The loss function\n",
        "    :type criterion: torch.nn.Module\n",
        "    :param optimizer: The optimizer\n",
        "    :type optimizer: torch.optim.Optimizer\n",
        "    :param scheduler: The learning rate scheduler\n",
        "    :type scheduler: torch.optim.lr_scheduler.StepLR\n",
        "    :param device: The device to use\n",
        "    :type device: torch.device\n",
        "    :param num_epochs: The number of epochs\n",
        "    :type num_epochs: int\n",
        "\n",
        "    :return: The trained model and the training history\n",
        "    :rtype: tuple\n",
        "    \"\"\"\n",
        "    history = {\n",
        "        \"train_loss\": [],\n",
        "        \"val_loss\": [],\n",
        "        \"val_acc\": []\n",
        "    }\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        loop = tqdm.tqdm(enumerate(train_loader),\n",
        "                         total=len(train_loader), leave=False)\n",
        "        for i, (images, labels) in loop:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            loop.set_description(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
        "            loop.set_postfix(loss=train_loss / (i + 1))\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        val_loss, val_acc, _ = validate(model, val_loader, criterion, device)\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
        "        print(f\"Train loss: {train_loss:.4f}\")\n",
        "        print(f\"Validation loss: {val_loss:.4f}\")\n",
        "        print(f\"Validation accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            checkpoint = {\n",
        "                \"epoch\": epoch + 1,\n",
        "                \"model\": model.state_dict(),\n",
        "                \"optimizer\": optimizer.state_dict(),\n",
        "                \"scheduler\": scheduler.state_dict(),\n",
        "                \"history\": history\n",
        "            }\n",
        "            torch.save(checkpoint, \"checkpoint.pth\")\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFPriGRxd42g"
      },
      "source": [
        "##### **Train the model**\n",
        "\n",
        "Call the `train` function to train the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7F-I14Ed42g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95564a31-e4e2-4f0d-e648-a1d2a9ed613d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10]\n",
            "Train loss: 1.6624\n",
            "Validation loss: 1.3398\n",
            "Validation accuracy: 0.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10]\n",
            "Train loss: 1.6688\n",
            "Validation loss: 1.3306\n",
            "Validation accuracy: 0.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10]\n",
            "Train loss: 1.6935\n",
            "Validation loss: 1.3204\n",
            "Validation accuracy: 0.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10]\n",
            "Train loss: 1.7084\n",
            "Validation loss: 1.3419\n",
            "Validation accuracy: 0.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10]\n",
            "Train loss: 1.6925\n",
            "Validation loss: 1.2846\n",
            "Validation accuracy: 0.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10]\n",
            "Train loss: 1.4991\n",
            "Validation loss: 1.1784\n",
            "Validation accuracy: 0.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10]\n",
            "Train loss: 1.4118\n",
            "Validation loss: 1.1623\n",
            "Validation accuracy: 0.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10]\n",
            "Train loss: 1.3588\n",
            "Validation loss: 1.1462\n",
            "Validation accuracy: 0.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10]\n",
            "Train loss: 1.3144\n",
            "Validation loss: 1.1382\n",
            "Validation accuracy: 0.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10]\n",
            "Train loss: 1.2897\n",
            "Validation loss: 1.1328\n",
            "Validation accuracy: 0.61%\n"
          ]
        }
      ],
      "source": [
        "model, history = train(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    device,\n",
        "    num_epochs=config[\"model_params\"][\"num_epochs\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHqIlL22d42g"
      },
      "source": [
        "#### **Plot the learning curve**\n",
        "\n",
        "Plot the training loss and validation loss using `matplotlib`, keep both the training loss and validation loss in the same plot.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UhFH7S_d42g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "cd9fa244-aed1-48da-ee4f-ddda2bdf9142"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(history[\"train_loss\"], label=\"Train loss\")\n",
        "plt.plot(history[\"val_loss\"], label=\"Validation loss\")\n",
        "plt.title(\"Loss curve\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmYrwmXOd42g"
      },
      "source": [
        "#### **Load the model from the checkpoint**\n",
        "\n",
        "Use `torch.load` to load the model from the checkpoint and use the `model.load_state_dict` method to load the model weights.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHsvHeAxd42g"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(\"checkpoint.pth\")[\"model\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcRgR9rBd42h"
      },
      "source": [
        "#### **Evaluate model performance**\n",
        "\n",
        "Now, we have trained the model. Call the `validate` function to validate the model and calculate the loss and predicted labels on the testing data.\n",
        "\n",
        "1. Use scikit-learn's `classification_report` function to evaluate the performance of the model. The `classification_report` function takes two inputs, `test_labels` and `predicted_labels`, and returns a report of the precision, recall, and F1-score of the model.\n",
        "2. Use the `confusion_matrix` function to get the confusion matrix of the model. It also takes two inputs, `test_labels` and `predicted_labels`, and returns the confusion matrix of the model. Use `ConfusionMatrixDisplay` to display the confusion matrix.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0KaFUhBd42h"
      },
      "outputs": [],
      "source": [
        "_, _, y_pred = validate(model, test_loader, criterion, device)\n",
        "y_test = [labels for _, labels in test_loader]\n",
        "y_test = torch.cat(y_test).numpy()\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(\n",
        "    y_test, y_pred), display_labels=classes)\n",
        "disp = disp.plot(xticks_rotation=45)\n",
        "plt.title('Confusion Matrix Test Data')\n",
        "plt.show()\n",
        "\n",
        "print('\\n\\n')\n",
        "print(classification_report(y_test, y_pred, target_names=classes))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}